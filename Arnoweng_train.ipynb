{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:16<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3707\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:32<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6302\n",
      "Saved Best Model with AUROC: 0.6302\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3391\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:32<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5294\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3425\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5842\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3429\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5657\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3350\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6657\n",
      "Saved Best Model with AUROC: 0.6657\n",
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3285\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6536\n",
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3318\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6261\n",
      "Epoch [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3287\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6724\n",
      "Saved Best Model with AUROC: 0.6724\n",
      "Epoch [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3285\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6687\n",
      "Epoch [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 63/63 [00:13<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3258\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:31<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6557\n",
      "Training Complete!\n",
      "Best Thresholds: [np.float32(0.05478248), np.float32(0.040272005), np.float32(0.061466575), np.float32(0.20306452), np.float32(0.21073325)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchvision.models import densenet121\n",
    "from read_data import ChestXrayDataSet\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ===================== CONSTANTS =====================\n",
    "DATA_DIR = \"C:/Users/zafer/OneDrive/Masaüstü/224NIH/dataset/images-224/images-224\"\n",
    "TRAIN_IMAGE_LIST = 'labels/train_list_balanced.txt'\n",
    "VAL_IMAGE_LIST = 'labels/val_list_balanced.txt'\n",
    "CKPT_PATH = ''  # Pretrained model path\n",
    "SAVE_PATH = 'best_model/5finding_trained_densenet121.pth.tar'  # Path to save the trained model\n",
    "N_CLASSES = 5\n",
    "#CLASS_NAMES = [\n",
    "#    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',\n",
    "#    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "#    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "#]\n",
    "CLASS_NAMES = [\"Emphysema\", \"Cardiomegaly\", \"Edema\", \"Effusion\", \"Atelectasis\"]\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "\n",
    "# ===================== CUSTOM CLAHE TRANSFORM =====================\n",
    "class CLAHETransform:\n",
    "    \"\"\"Apply CLAHE to an image.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img, dtype=np.uint8)  # Convert PIL image to numpy array with explicit dtype\n",
    "        if len(img.shape) == 3:  # For RGB images\n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            l = clahe.apply(l)\n",
    "            lab = cv2.merge((l, a, b))\n",
    "            img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "        else:  # For grayscale images\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            img = clahe.apply(img)\n",
    "        return Image.fromarray(img)  # Convert back to PIL image\n",
    "\n",
    "# ===================== UPDATED TRANSFORMS =====================\n",
    "def create_train_transforms():\n",
    "    \"\"\"Create transformations for training with enhanced augmentation.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        CLAHETransform(),  # Apply CLAHE\n",
    "        AutoAugment(AutoAugmentPolicy.IMAGENET),  # Advanced data augmentation\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def create_val_transforms():\n",
    "    \"\"\"Create transformations for validation with CLAHE.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        CLAHETransform(),  # Apply CLAHE\n",
    "        transforms.TenCrop(224),\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                          [0.229, 0.224, 0.225])(crop) for crop in crops]))\n",
    "    ])\n",
    "\n",
    "# ===================== DATA LOADERS =====================\n",
    "def get_dataloaders():\n",
    "    train_dataset = ChestXrayDataSet(data_dir=DATA_DIR, image_list_file=TRAIN_IMAGE_LIST,\n",
    "                                     transform=create_train_transforms())\n",
    "    val_dataset = ChestXrayDataSet(data_dir=DATA_DIR, image_list_file=VAL_IMAGE_LIST,\n",
    "                                   transform=create_val_transforms())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# ===================== MODEL DEFINITION =====================\n",
    "class DenseNet121(nn.Module):\n",
    "    \"\"\"DenseNet121 with a sigmoid activation for multi-label classification.\"\"\"\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Linear(num_ftrs, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet121(x)\n",
    "\n",
    "\n",
    "def load_pretrained_model():\n",
    "    \"\"\"Load a pretrained DenseNet121 model.\"\"\"\n",
    "    model = DenseNet121(N_CLASSES)\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        checkpoint = torch.load(CKPT_PATH, map_location=\"cuda:0\")\n",
    "        if 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            state_dict = {\n",
    "                k.replace('module.', '')\n",
    "                 .replace('norm.1', 'norm1')\n",
    "                 .replace('conv.1', 'conv1')\n",
    "                 .replace('norm.2', 'norm2')\n",
    "                 .replace('conv.2', 'conv2')\n",
    "                 .replace(\"classifier.0\",\"classifier\"): v\n",
    "                for k, v in state_dict.items()\n",
    "            }\n",
    "            model.load_state_dict(state_dict)\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        print(\"Loaded pretrained model.\")\n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def compute_optimal_thresholds(gt, pred):\n",
    "    \"\"\"\n",
    "    Compute optimal thresholds for each class based on validation set predictions.\n",
    "    Returns a list of thresholds for all classes.\n",
    "    \"\"\"\n",
    "    thresholds = []\n",
    "    for i in range(N_CLASSES):\n",
    "        fpr, tpr, thresh = roc_curve(gt[:, i], pred[:, i])\n",
    "        j_statistic = tpr - fpr\n",
    "        optimal_idx = np.argmax(j_statistic)\n",
    "        optimal_threshold = thresh[optimal_idx]\n",
    "        thresholds.append(optimal_threshold)\n",
    "    return thresholds\n",
    "\n",
    "# ===================== TRAINING LOOP =====================\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
    "    model = model.cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "    best_auroc = 0.0  # Initialize best_auroc\n",
    "    best_thresholds = None  # To store best thresholds\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        \n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        print(\"Evaluating on validation set...\")\n",
    "        val_auroc, gt, pred = evaluate_model(model, val_loader)\n",
    "        print(f\"Validation AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "        # Adjust learning rate based on validation performance\n",
    "        scheduler.step(val_auroc)\n",
    "\n",
    "        # Save Best Model and Thresholds\n",
    "        if val_auroc > best_auroc:\n",
    "            best_auroc = val_auroc\n",
    "            best_thresholds = compute_optimal_thresholds(gt, pred)\n",
    "            os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
    "            torch.save(model.state_dict(), SAVE_PATH)\n",
    "            print(f\"Saved Best Model with AUROC: {best_auroc:.4f}\")\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "    print(f\"Best Thresholds: {best_thresholds}\")\n",
    "    return best_thresholds\n",
    "\n",
    "\n",
    "\n",
    "# ===================== EVALUATE MODEL =====================\n",
    "def evaluate_model(model, val_loader):\n",
    "    \"\"\"Evaluate the model and compute AUROC.\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    gt, pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inp, target in tqdm(val_loader, desc=\"Evaluating\", leave=True):\n",
    "            target = target.cuda()\n",
    "            bs, n_crops, c, h, w = inp.size()\n",
    "            inp = inp.view(-1, c, h, w).cuda()\n",
    "\n",
    "            # Get raw logits and apply sigmoid\n",
    "            logits = model(inp)\n",
    "            output_mean = torch.sigmoid(logits.view(bs, n_crops, -1).mean(1))\n",
    "\n",
    "            gt.append(target.cpu())\n",
    "            pred.append(output_mean.cpu())\n",
    "\n",
    "    gt = torch.cat(gt).numpy()\n",
    "    pred = torch.cat(pred).numpy()\n",
    "    AUROCs = [roc_auc_score(gt[:, i], pred[:, i]) for i in range(N_CLASSES)]\n",
    "    return np.mean(AUROCs), gt, pred\n",
    "\n",
    "# ===================== MAIN SCRIPT =====================\n",
    "def main():\n",
    "    train_loader, val_loader = get_dataloaders()\n",
    "    model = load_pretrained_model()\n",
    "    train_model(model, train_loader, val_loader, NUM_EPOCHS, LEARNING_RATE)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_thresholds(pred, thresholds):\n",
    "    \"\"\"Apply class-specific thresholds to predictions.\"\"\"\n",
    "    return (pred > thresholds).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_thresholds \u001b[38;5;241m=\u001b[39m train_model(\u001b[43mmodel\u001b[49m, train_loader, val_loader, NUM_EPOCHS, LEARNING_RATE)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# For predictions:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m final_predictions \u001b[38;5;241m=\u001b[39m classify_with_thresholds(pred, best_thresholds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "best_thresholds = train_model(model, train_loader, val_loader, NUM_EPOCHS, LEARNING_RATE)\n",
    "# For predictions:\n",
    "final_predictions = classify_with_thresholds(pred, best_thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
